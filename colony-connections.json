{
  "exportedAt": "2026-02-19T21:30:02.724Z",
  "colonies": [
    {
      "id": "alpha",
      "name": "Alpha (General AI)",
      "stats": {
        "totalFindings": 3815,
        "totalEdges": 32229,
        "totalPheromones": 10983,
        "avgScore": 73.31544788113357
      },
      "findings": [
        {
          "id": "insight-1771533001833-2gzrpk",
          "title": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:30:01.833Z"
        },
        {
          "id": "insight-1771533001833-74rfnh",
          "title": "Emerging trend: efficiency with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:30:01.833Z"
        },
        {
          "id": "insight-1771533001832-0j3n4f",
          "title": "Emerging trend: retrieval-augmented with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:30:01.832Z"
        },
        {
          "id": "insight-1771533001830-m118dl",
          "title": "Emerging trend: prompt-engineering with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:30:01.830Z"
        },
        {
          "id": "insight-1771533001829-m63ffv",
          "title": "Emerging trend: state-space-models with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:30:01.829Z"
        },
        {
          "id": "web-2ae2aa60858dd99c",
          "title": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
          "summary": "",
          "source": "research-scout",
          "score": 71,
          "date": "2026-02-19T19:00:02.486Z"
        },
        {
          "id": "deep-synth-1771527430436-1dad5k",
          "title": "CONNECTION: SpaceX Acquires xAI, Announces Plans for Data Centers In Space ↔ What's the deal with sp",
          "summary": " WHY THEY'RE RELATED:",
          "source": "deep-synthesis-ant",
          "score": 89,
          "date": "2026-02-19T18:57:10.436Z"
        },
        {
          "id": "deep-synth-1771527414744-y1dh5e",
          "title": "CONNECTION: What is RLHF? - Reinforcement Learning from Human Feedback Explained - AWS ↔ AI research",
          "summary": " WHY THEY'RE RELATED:",
          "source": "deep-synthesis-ant",
          "score": 90,
          "date": "2026-02-19T18:56:54.744Z"
        },
        {
          "id": "deep-synth-1771527383063-7vod21",
          "title": "CONNECTION: [2501.06322] Multi-Agent Collaboration Mechanisms: A Survey of LLMs ↔ Nemotron 3 Nano: O",
          "summary": " WHY THEY'RE RELATED:",
          "source": "deep-synthesis-ant",
          "score": 90,
          "date": "2026-02-19T18:56:23.063Z"
        },
        {
          "id": "deep-synth-1771527368039-au87xz",
          "title": "CONNECTION: [2501.06322] Multi-Agent Collaboration Mechanisms: A Survey of LLMs ↔ Agentic AI, explai",
          "summary": " WHY THEY'RE RELATED:",
          "source": "deep-synthesis-ant",
          "score": 90,
          "date": "2026-02-19T18:56:08.039Z"
        },
        {
          "id": "web-dff8e433360c152c",
          "title": "In addition, the inclusion of the IoT-20 dataset ensures relevance to contemporary network security ",
          "summary": "",
          "source": "research-scout",
          "score": 77,
          "date": "2026-02-19T17:00:02.837Z"
        },
        {
          "id": "insight-1771518601867-swfvx8",
          "title": "Potential breakthrough: What is a Transformer Model? | IBM - score 81",
          "summary": "",
          "source": "synthesis-ant",
          "score": 81,
          "date": "2026-02-19T16:30:01.867Z"
        },
        {
          "id": "insight-1771518601770-9x73kt",
          "title": "Potential breakthrough: RLHF vs RLAIF vs RLVR: The Three Ways to Teach AI Models - Floating Bytes - ",
          "summary": "",
          "source": "synthesis-ant",
          "score": 83,
          "date": "2026-02-19T16:30:01.770Z"
        },
        {
          "id": "insight-1771518601770-basdob",
          "title": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:30:01.770Z"
        },
        {
          "id": "insight-1771518601770-bz3x1u",
          "title": "Emerging trend: efficiency with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:30:01.770Z"
        },
        {
          "id": "insight-1771518601770-akie8z",
          "title": "Emerging trend: retrieval-augmented with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:30:01.770Z"
        },
        {
          "id": "insight-1771518601770-216wd4",
          "title": "Emerging trend: prompt-engineering with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:30:01.770Z"
        },
        {
          "id": "insight-1771518601770-2lim8n",
          "title": "Emerging trend: state-space-models with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:30:01.770Z"
        },
        {
          "id": "web-5a19838b2adf8845",
          "title": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
          "summary": "",
          "source": "research-scout",
          "score": 81,
          "date": "2026-02-19T16:00:02.636Z"
        },
        {
          "id": "web-11370417f715f333",
          "title": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
          "summary": "",
          "source": "research-scout",
          "score": 83,
          "date": "2026-02-19T14:00:02.413Z"
        }
      ],
      "connections": [
        {
          "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
          "to": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on stan",
          "fromId": "hf-2602.15927",
          "toId": "hf-2602.16666",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
          "to": "Long-horizon multimodal agents depend on external memory; however, similarity-based retrieval often ",
          "fromId": "hf-2602.15927",
          "toId": "hf-2602.16493",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
          "to": "We report on the temporal changes in undergraduate-level physics programs at Korean universities fro",
          "fromId": "hf-2602.15927",
          "toId": "s2-41b5a001b9bc346cbf378e3c050316827828233b",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
          "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
          "fromId": "hf-2602.15927",
          "toId": "hf-2602.10210",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
          "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
          "fromId": "hf-2602.15927",
          "toId": "hf-2602.15156",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on stan",
          "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
          "fromId": "hf-2602.16666",
          "toId": "hf-2602.10210",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent re",
          "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
          "fromId": "hf-2602.16301",
          "toId": "hf-2602.10210",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent re",
          "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
          "fromId": "hf-2602.16301",
          "toId": "hf-2602.15156",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "We report on the temporal changes in undergraduate-level physics programs at Korean universities fro",
          "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
          "fromId": "s2-41b5a001b9bc346cbf378e3c050316827828233b",
          "toId": "hf-2602.10210",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reas",
          "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
          "fromId": "hf-2602.15382",
          "toId": "hf-2602.10210",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reas",
          "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
          "fromId": "hf-2602.15382",
          "toId": "hf-2602.15156",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:00:03"
        },
        {
          "from": "[2024/02] LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environme",
          "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
          "fromId": "web-00a86862246b75be",
          "toId": "web-11370417f715f333",
          "weight": 0.7330729166666666,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "[2024/02] LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environme",
          "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
          "fromId": "web-00a86862246b75be",
          "toId": "web-5a19838b2adf8845",
          "weight": 0.7044270833333334,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "[2024/02] LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environme",
          "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
          "fromId": "web-00a86862246b75be",
          "toId": "web-2ae2aa60858dd99c",
          "weight": 0.7278645833333334,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "We then introduce a conceptual framework based on three interaction regimes—competition, collaborati",
          "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
          "fromId": "web-17eb498ee3ae1c23",
          "toId": "web-11370417f715f333",
          "weight": 0.73828125,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "We then introduce a conceptual framework based on three interaction regimes—competition, collaborati",
          "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
          "fromId": "web-17eb498ee3ae1c23",
          "toId": "web-2ae2aa60858dd99c",
          "weight": 0.75390625,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "The predecessor to Mamba, the S4 model [6], was <strong>the first SSM to show promising results in t",
          "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
          "fromId": "web-1d616ea7698e2ed2",
          "toId": "web-11370417f715f333",
          "weight": 0.7552083333333334,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "The predecessor to Mamba, the S4 model [6], was <strong>the first SSM to show promising results in t",
          "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
          "fromId": "web-1d616ea7698e2ed2",
          "toId": "web-5a19838b2adf8845",
          "weight": 0.71875,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "The predecessor to Mamba, the S4 model [6], was <strong>the first SSM to show promising results in t",
          "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
          "fromId": "web-1d616ea7698e2ed2",
          "toId": "web-2ae2aa60858dd99c",
          "weight": 0.7109375,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "These LLM-based Multi-Agent Systems (MASs) <strong>enable groups of intelligent agents to coordinate",
          "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
          "fromId": "web-21c4a356615bd040",
          "toId": "web-11370417f715f333",
          "weight": 0.7330729166666666,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "These LLM-based Multi-Agent Systems (MASs) <strong>enable groups of intelligent agents to coordinate",
          "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
          "fromId": "web-21c4a356615bd040",
          "toId": "web-5a19838b2adf8845",
          "weight": 0.7200520833333334,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "These LLM-based Multi-Agent Systems (MASs) <strong>enable groups of intelligent agents to coordinate",
          "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
          "fromId": "web-21c4a356615bd040",
          "toId": "web-2ae2aa60858dd99c",
          "weight": 0.80859375,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "<strong>Large language model-based multi-agent systems have shown great abilities across various tas",
          "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
          "fromId": "web-2f7bfc69348d4385",
          "toId": "web-11370417f715f333",
          "weight": 0.76953125,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "<strong>Large language model-based multi-agent systems have shown great abilities across various tas",
          "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
          "fromId": "web-2f7bfc69348d4385",
          "toId": "web-5a19838b2adf8845",
          "weight": 0.72265625,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "<strong>Large language model-based multi-agent systems have shown great abilities across various tas",
          "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
          "fromId": "web-2f7bfc69348d4385",
          "toId": "web-2ae2aa60858dd99c",
          "weight": 0.7643229166666666,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "In our previous blog post, we introduced Volcano Engine Reinforcement Learning for LLMs (verl) 0.3.0",
          "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
          "fromId": "web-3650efa34ab90d14",
          "toId": "web-11370417f715f333",
          "weight": 0.7799479166666666,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "In our previous blog post, we introduced Volcano Engine Reinforcement Learning for LLMs (verl) 0.3.0",
          "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
          "fromId": "web-3650efa34ab90d14",
          "toId": "web-5a19838b2adf8845",
          "weight": 0.7330729166666666,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "In our previous blog post, we introduced Volcano Engine Reinforcement Learning for LLMs (verl) 0.3.0",
          "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
          "fromId": "web-3650efa34ab90d14",
          "toId": "web-2ae2aa60858dd99c",
          "weight": 0.7174479166666666,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "... Structured state space sequence models (S4) are <strong>a recent class of sequence models for de",
          "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
          "fromId": "web-3d182c8a65d6c5bb",
          "toId": "web-11370417f715f333",
          "weight": 0.7578125,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        },
        {
          "from": "... Structured state space sequence models (S4) are <strong>a recent class of sequence models for de",
          "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
          "fromId": "web-3d182c8a65d6c5bb",
          "toId": "web-5a19838b2adf8845",
          "weight": 0.7317708333333334,
          "type": "jenny_coupler",
          "date": "2026-02-19 20:00:02"
        }
      ],
      "breakthroughs": [
        {
          "topic": "web-5a19838b2adf8845",
          "strength": 0.6698358639690458,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-19T16:30:01.612Z"
        },
        {
          "topic": "web-11370417f715f333",
          "strength": 0.6863738923994217,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-19T16:30:01.464Z"
        },
        {
          "topic": "web-2228e576bf95e522",
          "strength": 0.3619199988244031,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-19T00:30:01.525Z"
        },
        {
          "topic": "web-e966420a37acc61d",
          "strength": 0.371581088038905,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-19T00:15:02.852Z"
        },
        {
          "topic": "web-e966420a37acc61d",
          "strength": 0.3715831234831065,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-19T00:15:02.808Z"
        },
        {
          "topic": "web-e966420a37acc61d",
          "strength": 0.37158053066769114,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T21:15:01.892Z"
        },
        {
          "topic": "web-e966420a37acc61d",
          "strength": 0.37157831357713905,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T20:30:02.144Z"
        },
        {
          "topic": "web-24ace1ccaf1a4193",
          "strength": 0.21585599234294492,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T12:30:01.729Z"
        },
        {
          "topic": "oalex-W3044091938",
          "strength": 0.19610672961795564,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T10:06:06.010Z"
        },
        {
          "topic": "oalex-W3207559276",
          "strength": 0.19604337559039872,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T10:05:36.930Z"
        },
        {
          "topic": "web-1eaf00d7a315d346",
          "strength": 0.1908388884934991,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T08:30:02.098Z"
        },
        {
          "topic": "web-1eaf00d7a315d346",
          "strength": 0.19083855558595067,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T08:30:01.941Z"
        },
        {
          "topic": "web-1c2445d4eb57c6f7",
          "strength": 0.19083830749598965,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T08:30:01.824Z"
        },
        {
          "topic": "hf-2602.09877",
          "strength": 0.18097603452439504,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T08:05:39.511Z"
        },
        {
          "topic": "oalex-W2912320302",
          "strength": 0.16713595874947257,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T06:06:19.380Z"
        }
      ],
      "deepInsights": []
    },
    {
      "id": "beta",
      "name": "Beta (SQL/Speed)",
      "stats": {
        "totalFindings": 3059,
        "totalEdges": 26241,
        "totalPheromones": 8217,
        "avgScore": 71.58050356870437
      },
      "findings": [
        {
          "id": "insight-1771533601282-enf96y",
          "title": "Emerging trend: cost-reduction with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:40:01.282Z"
        },
        {
          "id": "insight-1771533601282-nkco3a",
          "title": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:40:01.282Z"
        },
        {
          "id": "insight-1771533601282-z09d51",
          "title": "Emerging trend: efficiency with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:40:01.282Z"
        },
        {
          "id": "insight-1771533601282-gv7wgz",
          "title": "Emerging trend: retrieval-augmented with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:40:01.282Z"
        },
        {
          "id": "insight-1771533601276-emf6gh",
          "title": "Emerging trend: state-space-models with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T20:40:01.276Z"
        },
        {
          "id": "insight-1771519201958-jtqop2",
          "title": "Emerging trend: memory-systems with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:40:01.958Z"
        },
        {
          "id": "insight-1771519201958-jv7ol2",
          "title": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:40:01.958Z"
        },
        {
          "id": "insight-1771519201958-0973k4",
          "title": "Emerging trend: efficiency with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:40:01.958Z"
        },
        {
          "id": "insight-1771519201958-8in06b",
          "title": "Emerging trend: retrieval-augmented with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:40:01.958Z"
        },
        {
          "id": "insight-1771519201949-ojmf6y",
          "title": "Emerging trend: state-space-models with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T16:40:01.949Z"
        },
        {
          "id": "insight-1771504801451-bvpimn",
          "title": "Emerging trend: efficiency with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 99,
          "date": "2026-02-19T12:40:01.451Z"
        },
        {
          "id": "insight-1771504801451-ojs1wu",
          "title": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 99,
          "date": "2026-02-19T12:40:01.451Z"
        },
        {
          "id": "insight-1771504801450-u3uka4",
          "title": "Emerging trend: memory-systems with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 99,
          "date": "2026-02-19T12:40:01.450Z"
        },
        {
          "id": "insight-1771504801450-6klz1g",
          "title": "Emerging trend: cost-reduction with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 99,
          "date": "2026-02-19T12:40:01.450Z"
        },
        {
          "id": "insight-1771504801447-1dpubg",
          "title": "Emerging trend: uncategorized with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 99,
          "date": "2026-02-19T12:40:01.447Z"
        },
        {
          "id": "insight-1771490401226-7xn0lp",
          "title": "Emerging trend: cost-reduction with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T08:40:01.226Z"
        },
        {
          "id": "insight-1771490401226-ublbsm",
          "title": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T08:40:01.226Z"
        },
        {
          "id": "insight-1771490401226-k4k58f",
          "title": "Emerging trend: efficiency with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T08:40:01.226Z"
        },
        {
          "id": "insight-1771490401226-p35i8f",
          "title": "Emerging trend: retrieval-augmented with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T08:40:01.226Z"
        },
        {
          "id": "insight-1771490401217-msy0rc",
          "title": "Emerging trend: state-space-models with 10 related findings in the last 24h",
          "summary": "",
          "source": "synthesis-ant",
          "score": 100,
          "date": "2026-02-19T08:40:01.217Z"
        }
      ],
      "connections": [
        {
          "from": "Emerging trend: memory-systems with 10 related findings in the last 24h",
          "to": "Abstract: Latency optimization is crucial for deploying large language models (LLMs) in edge computi",
          "fromId": "insight-1771389602128-hei8uc",
          "toId": "s2-70ce98fdd37be3c0bf9cdfb81ea5a1f0d333da75",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: memory-systems with 10 related findings in the last 24h",
          "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
          "fromId": "insight-1771389602128-hei8uc",
          "toId": "hf-2602.15156",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Large Language Models (LLMs) have attracted extensive attention due to their remarkable performance ",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-5be7e6b04c5a240cff340034aae2b57c677e211f",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Sequence modeling is a crucial area across various domains, including Natural Language Processing (N",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-ba4c5a116d07b37dea1046b6d16a60cb2d01cd47",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Long-short range time series forecasting is essential for predicting future trends and patterns over",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-3e0aa05e9c0ee4fc6b3c67887960a9ef18c502d4",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Time series forecasting has made significant advances, including with Transformer-based models. The ",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-4ea7378fc3cb0c6e7092ae162cbd1537ae637597",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "CONNECTION: Get multimodal embeddings | Generative AI on Vertex AI | Google Cloud Documentation ↔ An",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "deep-synth-1771441567432-jhohn6",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "CONNECTION: Get multimodal embeddings | Generative AI on Vertex AI | Google Cloud Documentation ↔ An",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "deep-synth-1771420001613-jqmoc6",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Powerful foundation models, including large language models (LLMs), with Transformer architectures h",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-68719e9df3d4821a1afedf9c18b0148e51800f71",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "The Large Language Model (LLM) is widely employed for tasks such as intelligent assistants, text sum",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-1f43c1f42dd5505f27c0b36c99e6e6fa01f87ad5",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Long-term time series forecasting (LTSF) provides longer insights into future trends and patterns. O",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-bf4d1d11c0ee0c4335e8ae6f0e433e7ddd20be87",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Recent advancements in multivariate time series forecasting have been propelled by Linear-based, Tra",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-b7ed7845bfa63b07899d44434a479f08f80ca268",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "In recent years, Transformers have become the de-facto architecture for long-term sequence forecasti",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-9823f4a4c66c0607994a9f9722ec3c4cf8c1f2e4",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "In recent years, the rapid advancement of large-scale pre-trained language models based on transform",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-ac2de949adce88d5933675560d0ac449d116dea2",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Time-series forecasting has seen significant advancements with the introduction of token prediction ",
          "fromId": "insight-1771389602128-xld5wx",
          "toId": "s2-c86d4019359e33d8e00633bcb81c5722924fbbbf",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Large Language Models (LLMs) have attracted extensive attention due to their remarkable performance ",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-5be7e6b04c5a240cff340034aae2b57c677e211f",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Sequence modeling is a crucial area across various domains, including Natural Language Processing (N",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-ba4c5a116d07b37dea1046b6d16a60cb2d01cd47",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Long-short range time series forecasting is essential for predicting future trends and patterns over",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-3e0aa05e9c0ee4fc6b3c67887960a9ef18c502d4",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Time series forecasting has made significant advances, including with Transformer-based models. The ",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-4ea7378fc3cb0c6e7092ae162cbd1537ae637597",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "CONNECTION: Get multimodal embeddings | Generative AI on Vertex AI | Google Cloud Documentation ↔ An",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "deep-synth-1771441567432-jhohn6",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "CONNECTION: Get multimodal embeddings | Generative AI on Vertex AI | Google Cloud Documentation ↔ An",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "deep-synth-1771420001613-jqmoc6",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Powerful foundation models, including large language models (LLMs), with Transformer architectures h",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-68719e9df3d4821a1afedf9c18b0148e51800f71",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "The Large Language Model (LLM) is widely employed for tasks such as intelligent assistants, text sum",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-1f43c1f42dd5505f27c0b36c99e6e6fa01f87ad5",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Long-term time series forecasting (LTSF) provides longer insights into future trends and patterns. O",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-bf4d1d11c0ee0c4335e8ae6f0e433e7ddd20be87",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Recent advancements in multivariate time series forecasting have been propelled by Linear-based, Tra",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-b7ed7845bfa63b07899d44434a479f08f80ca268",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "In recent years, Transformers have become the de-facto architecture for long-term sequence forecasti",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-9823f4a4c66c0607994a9f9722ec3c4cf8c1f2e4",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "In recent years, the rapid advancement of large-scale pre-trained language models based on transform",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-ac2de949adce88d5933675560d0ac449d116dea2",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
          "to": "Time-series forecasting has seen significant advancements with the introduction of token prediction ",
          "fromId": "insight-1771504801451-ojs1wu",
          "toId": "s2-c86d4019359e33d8e00633bcb81c5722924fbbbf",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: memory-systems with 10 related findings in the last 24h",
          "to": "Large Language Models (LLMs) have attracted extensive attention due to their remarkable performance ",
          "fromId": "insight-1771504801450-u3uka4",
          "toId": "s2-5be7e6b04c5a240cff340034aae2b57c677e211f",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Emerging trend: memory-systems with 10 related findings in the last 24h",
          "to": "Sequence modeling is a crucial area across various domains, including Natural Language Processing (N",
          "fromId": "insight-1771504801450-u3uka4",
          "toId": "s2-ba4c5a116d07b37dea1046b6d16a60cb2d01cd47",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        }
      ],
      "breakthroughs": [
        {
          "topic": "PostgreSQL Hash Chain Audit Pattern",
          "strength": 0.23390043139100608,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T12:25:01.969Z"
        },
        {
          "topic": "Merkle Tree Anchors for Audit Checkpoints",
          "strength": 0.22158860946331416,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T10:22:40.049Z"
        },
        {
          "topic": "PostgreSQL Time-Series Partitioning for Audit Logs",
          "strength": 0.22651266739388887,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T10:22:39.996Z"
        },
        {
          "topic": "PostgreSQL Hash Chain Audit Pattern",
          "strength": 0.23389879929146792,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T10:22:39.938Z"
        },
        {
          "topic": "oalex-W2166798417",
          "strength": 0.08437247068752089,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T08:40:01.396Z"
        },
        {
          "topic": "oalex-W2181465509",
          "strength": 0.1954361716461569,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T08:40:01.322Z"
        },
        {
          "topic": "oalex-W2115765852",
          "strength": 0.19543593495138126,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T08:40:01.213Z"
        },
        {
          "topic": "hf-2602.12036",
          "strength": 0.18055214092444333,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T08:12:08.257Z"
        },
        {
          "topic": "hf-2602.09021",
          "strength": 0.1804544605628336,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T08:11:19.553Z"
        },
        {
          "topic": "oalex-W2115765852",
          "strength": 0.16622267690023126,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T06:08:06.041Z"
        },
        {
          "topic": "oalex-W4321013654",
          "strength": 0.1537521403657728,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T04:11:07.257Z"
        },
        {
          "topic": "oalex-W4385571689",
          "strength": 0.14187593409058244,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T02:10:32.260Z"
        },
        {
          "topic": "oalex-W1978762354",
          "strength": 0.12093360448234089,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-17T20:40:02.027Z"
        },
        {
          "topic": "oalex-W3120392574",
          "strength": 0.12093353057849408,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-17T20:40:01.972Z"
        },
        {
          "topic": "oalex-W2141114982",
          "strength": 0.12093345264357726,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-17T20:40:01.914Z"
        }
      ],
      "deepInsights": []
    },
    {
      "id": "gamma",
      "name": "Gamma (Evolutionary)",
      "stats": {
        "totalFindings": 2417,
        "totalEdges": 25852,
        "totalPheromones": 8001,
        "avgScore": 70.36867651875603
      },
      "findings": [
        {
          "id": "arxiv-2602.16307v1",
          "title": "This study investigates generative artificial intelligence (GenAI) usage of university students who ",
          "summary": "",
          "source": "arxiv",
          "score": 80,
          "date": "2026-02-19 20:34:13"
        },
        {
          "id": "arxiv-2602.16584v1",
          "title": "There is growing evidence that independently trained AI systems come to represent the world in the s",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 20:34:13"
        },
        {
          "id": "arxiv-2602.16664v1",
          "title": "Adversarial diffusion and diffusion-inversion methods have advanced unpaired image-to-image translat",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 20:34:09"
        },
        {
          "id": "arxiv-2602.16607v1",
          "title": "Municipal meeting minutes are formal records documenting the discussions and decisions of local gove",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 20:34:06"
        },
        {
          "id": "arxiv-2602.16612v1",
          "title": "Abstracting from a low level to a more explanatory high level of description, and ideally while pres",
          "summary": "",
          "source": "arxiv",
          "score": 80,
          "date": "2026-02-19 20:34:06"
        },
        {
          "id": "arxiv-2602.16614v1",
          "title": "The distribution of meteor magnitudes is known to follow an exponential distribution, where the base",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 20:34:06"
        },
        {
          "id": "arxiv-2602.16636v1",
          "title": "Understanding mechanisms of ion transport in bulk materials is central to designing next-generation ",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 20:34:06"
        },
        {
          "id": "arxiv-2602.16650v1",
          "title": "Polymer literature contains a large and growing body of experimental knowledge, yet much of it is bu",
          "summary": "",
          "source": "arxiv",
          "score": 80,
          "date": "2026-02-19 20:34:06"
        },
        {
          "id": "arxiv-2602.16673v1",
          "title": "Clustering-based Approximate Nearest Neighbor Search (ANNS) organizes a set of points into partition",
          "summary": "",
          "source": "arxiv",
          "score": 80,
          "date": "2026-02-19 20:34:02"
        },
        {
          "id": "hf-2602.16704",
          "title": "Fast weight architectures offer a promising alternative to attention-based transformers for long-con",
          "summary": "",
          "source": "huggingface",
          "score": 70,
          "date": "2026-02-19 20:14:01"
        },
        {
          "id": "arxiv-2602.16617v1",
          "title": "Exciton transfer dynamics between chromophores depends on excitonic coupling, which is governed by r",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 16:34:15"
        },
        {
          "id": "arxiv-2602.16618v1",
          "title": "In principle, machine learning (ML) can be used to obtain any electronic property of a many-body sys",
          "summary": "",
          "source": "arxiv",
          "score": 75,
          "date": "2026-02-19 16:34:15"
        },
        {
          "id": "arxiv-2602.16619v1",
          "title": "Dubé introduced cone decompositions and their Macaulay constants and used them to obtain an upper bo",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 16:34:15"
        },
        {
          "id": "arxiv-2602.16627v1",
          "title": "We develop the theoretical model that describes dynamic non-equilibrium effects of external inertial",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 16:34:15"
        },
        {
          "id": "arxiv-2602.16628v1",
          "title": "Cerium hydride has a variety of interesting properties, including a known lattice contraction and de",
          "summary": "",
          "source": "arxiv",
          "score": 75,
          "date": "2026-02-19 16:34:15"
        },
        {
          "id": "arxiv-2602.16647v1",
          "title": "We investigated the initial growth of TiTe$_2$ on Au(111) from sub-monolayer to multi-layer coverage",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 16:34:15"
        },
        {
          "id": "arxiv-2602.16657v1",
          "title": "We consider the phenomenon of string breaking in the context of the spatial Wilson loops using the g",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 16:34:15"
        },
        {
          "id": "arxiv-2602.16694v1",
          "title": "We continue the study of flux tubes in confining gauge theories placed in a rigid AdS background, fo",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 16:34:15"
        },
        {
          "id": "arxiv-2602.16672v1",
          "title": "This study investigates how target geometry and material influence pion and muon production from an ",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 16:34:12"
        },
        {
          "id": "arxiv-2602.16706v1",
          "title": "Motivated by observational evidence from JWST and theoretical results from cosmological simulations,",
          "summary": "",
          "source": "arxiv",
          "score": 70,
          "date": "2026-02-19 16:34:05"
        }
      ],
      "connections": [
        {
          "from": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute ",
          "to": "Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video c",
          "fromId": "arxiv-2602.15814v1",
          "toId": "arxiv-2602.16711v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute ",
          "to": "Ab initio auxiliary-field quantum Monte Carlo (AFQMC) is a systematically improvable many-body metho",
          "fromId": "arxiv-2602.15814v1",
          "toId": "arxiv-2602.16679v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute ",
          "to": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
          "fromId": "arxiv-2602.15814v1",
          "toId": "hf-2602.15927",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute ",
          "to": "Long-horizon multimodal agents depend on external memory; however, similarity-based retrieval often ",
          "fromId": "arxiv-2602.15814v1",
          "toId": "hf-2602.16493",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute ",
          "to": "Retrieval-augmented generation (RAG) has gained wide attention as the key component to improve gener",
          "fromId": "arxiv-2602.15814v1",
          "toId": "s2-1b50e38b494509105435a67a99c2cadb236220b5",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute ",
          "to": "With the emergence of large language models, such as LLaMA and OpenAI GPT-3, In-Context Learning (IC",
          "fromId": "arxiv-2602.15814v1",
          "toId": "s2-bd6f1603a8786134109f114ce13d0006ce2d36f6",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute ",
          "to": "Abstract Retrieval Augmented Language Models (RALMs) have gained significant attention for their abi",
          "fromId": "arxiv-2602.15814v1",
          "toId": "s2-a6f3b65fba3ceaf80f2965e0358e3367bc6f185d",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute ",
          "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
          "fromId": "arxiv-2602.15814v1",
          "toId": "hf-2602.15156",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Position bias has proven to be a prevalent issue of modern language models (LMs), where the models p",
          "to": "Retrieval-augmented generation (RAG) has gained wide attention as the key component to improve gener",
          "fromId": "s2-6baf554c223cb4eea666efa2d1eb507a60823808",
          "toId": "s2-1b50e38b494509105435a67a99c2cadb236220b5",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Position bias has proven to be a prevalent issue of modern language models (LMs), where the models p",
          "to": "With the emergence of large language models, such as LLaMA and OpenAI GPT-3, In-Context Learning (IC",
          "fromId": "s2-6baf554c223cb4eea666efa2d1eb507a60823808",
          "toId": "s2-bd6f1603a8786134109f114ce13d0006ce2d36f6",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "Position bias has proven to be a prevalent issue of modern language models (LMs), where the models p",
          "to": "Abstract Retrieval Augmented Language Models (RALMs) have gained significant attention for their abi",
          "fromId": "s2-6baf554c223cb4eea666efa2d1eb507a60823808",
          "toId": "s2-a6f3b65fba3ceaf80f2965e0358e3367bc6f185d",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Current vision-language models (VLMs) still exhibit inferior performance on knowledge-intensive task",
          "fromId": "deep-synth-1771445715577-hr5uh3",
          "toId": "s2-898466d43a0dfee3ea9d714094d51afd172f1461",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processi",
          "fromId": "deep-synth-1771445715577-hr5uh3",
          "toId": "arxiv-2602.16640v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. Whi",
          "fromId": "deep-synth-1771445715577-hr5uh3",
          "toId": "arxiv-2602.16702v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
          "fromId": "deep-synth-1771445715577-hr5uh3",
          "toId": "hf-2602.10210",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
          "fromId": "deep-synth-1771445715577-hr5uh3",
          "toId": "hf-2602.15156",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Current vision-language models (VLMs) still exhibit inferior performance on knowledge-intensive task",
          "fromId": "deep-synth-1771424116806-o6l5li",
          "toId": "s2-898466d43a0dfee3ea9d714094d51afd172f1461",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processi",
          "fromId": "deep-synth-1771424116806-o6l5li",
          "toId": "arxiv-2602.16640v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. Whi",
          "fromId": "deep-synth-1771424116806-o6l5li",
          "toId": "arxiv-2602.16702v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
          "fromId": "deep-synth-1771424116806-o6l5li",
          "toId": "hf-2602.10210",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
          "fromId": "deep-synth-1771424116806-o6l5li",
          "toId": "hf-2602.15156",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Current vision-language models (VLMs) still exhibit inferior performance on knowledge-intensive task",
          "fromId": "deep-synth-1771424133851-3y3x1g",
          "toId": "s2-898466d43a0dfee3ea9d714094d51afd172f1461",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processi",
          "fromId": "deep-synth-1771424133851-3y3x1g",
          "toId": "arxiv-2602.16640v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. Whi",
          "fromId": "deep-synth-1771424133851-3y3x1g",
          "toId": "arxiv-2602.16702v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
          "fromId": "deep-synth-1771424133851-3y3x1g",
          "toId": "hf-2602.10210",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
          "fromId": "deep-synth-1771424133851-3y3x1g",
          "toId": "hf-2602.15156",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Current vision-language models (VLMs) still exhibit inferior performance on knowledge-intensive task",
          "fromId": "deep-synth-1771445779166-bnokg6",
          "toId": "s2-898466d43a0dfee3ea9d714094d51afd172f1461",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processi",
          "fromId": "deep-synth-1771445779166-bnokg6",
          "toId": "arxiv-2602.16640v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. Whi",
          "fromId": "deep-synth-1771445779166-bnokg6",
          "toId": "arxiv-2602.16702v1",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        },
        {
          "from": "CONNECTION: Evolutionary Algorithms for Parameter Optimization—Thirty Years Later | Evolutionary Com",
          "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
          "fromId": "deep-synth-1771445779166-bnokg6",
          "toId": "hf-2602.10210",
          "weight": 0.5,
          "type": "cross_cluster",
          "date": "2026-02-19 20:10:02"
        }
      ],
      "breakthroughs": [
        {
          "topic": "oalex-W3015606043",
          "strength": 0.19553075096629358,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T10:11:41.155Z"
        },
        {
          "topic": "s2-1df0f2e6e83b77807343793b66466d9c2571534a",
          "strength": 0.19524412632908394,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T10:09:29.129Z"
        },
        {
          "topic": "s2-0b25979bf487cbc9334e0e94031cdac83d4f28dd",
          "strength": 0.1952250475714077,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T10:09:20.334Z"
        },
        {
          "topic": "s2-d0489fd7c5ff833e08969341ae6e5fa1d0e6dd2a",
          "strength": 0.1951966422245158,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T10:09:07.238Z"
        },
        {
          "topic": "arxiv-2602.15010v1",
          "strength": 0.16638560875157293,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T06:09:34.289Z"
        },
        {
          "topic": "oalex-W2141955344",
          "strength": 0.1536782101996726,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-18T04:10:24.044Z"
        },
        {
          "topic": "hf-2602.10560",
          "strength": 0.0462855196206401,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-16T22:10:21.190Z"
        },
        {
          "topic": "oalex-W4292083457",
          "strength": 0.03638378246838815,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-16T16:09:17.648Z"
        },
        {
          "topic": "s2-b5d553aa0fc8e53c060014d399b2a2cde052dcf4",
          "strength": 0.03358338908015767,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-16T14:09:09.407Z"
        },
        {
          "topic": "s2-28eb18717cfa257f0fc49fb9512c48279cafa031",
          "strength": 0.02251154762756371,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-16T04:09:09.122Z"
        },
        {
          "topic": "oalex-W4387835442",
          "strength": 0.01918480183216896,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-16T00:09:17.221Z"
        },
        {
          "topic": "oalex-W2159398820",
          "strength": 0.017711521910992047,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-15T22:09:25.950Z"
        },
        {
          "topic": "oalex-W3135588948",
          "strength": 0.016354467199301708,
          "type": "breakthrough",
          "insight": "",
          "source": "",
          "date": "2026-02-15T20:09:51.663Z"
        }
      ],
      "deepInsights": []
    }
  ],
  "topConnections": [
    {
      "from": "These LLM-based Multi-Agent Systems (MASs) <strong>enable groups of intelligent agents to coordinate",
      "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
      "fromId": "web-21c4a356615bd040",
      "toId": "web-2ae2aa60858dd99c",
      "weight": 0.80859375,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "In our previous blog post, we introduced Volcano Engine Reinforcement Learning for LLMs (verl) 0.3.0",
      "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
      "fromId": "web-3650efa34ab90d14",
      "toId": "web-11370417f715f333",
      "weight": 0.7799479166666666,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "<strong>Large language model-based multi-agent systems have shown great abilities across various tas",
      "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
      "fromId": "web-2f7bfc69348d4385",
      "toId": "web-11370417f715f333",
      "weight": 0.76953125,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "<strong>Large language model-based multi-agent systems have shown great abilities across various tas",
      "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
      "fromId": "web-2f7bfc69348d4385",
      "toId": "web-2ae2aa60858dd99c",
      "weight": 0.7643229166666666,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "... Structured state space sequence models (S4) are <strong>a recent class of sequence models for de",
      "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
      "fromId": "web-3d182c8a65d6c5bb",
      "toId": "web-11370417f715f333",
      "weight": 0.7578125,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "The predecessor to Mamba, the S4 model [6], was <strong>the first SSM to show promising results in t",
      "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
      "fromId": "web-1d616ea7698e2ed2",
      "toId": "web-11370417f715f333",
      "weight": 0.7552083333333334,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "We then introduce a conceptual framework based on three interaction regimes—competition, collaborati",
      "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
      "fromId": "web-17eb498ee3ae1c23",
      "toId": "web-2ae2aa60858dd99c",
      "weight": 0.75390625,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "We then introduce a conceptual framework based on three interaction regimes—competition, collaborati",
      "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
      "fromId": "web-17eb498ee3ae1c23",
      "toId": "web-11370417f715f333",
      "weight": 0.73828125,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "[2024/02] LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environme",
      "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
      "fromId": "web-00a86862246b75be",
      "toId": "web-11370417f715f333",
      "weight": 0.7330729166666666,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "These LLM-based Multi-Agent Systems (MASs) <strong>enable groups of intelligent agents to coordinate",
      "to": "RLHF stands for <strong>Reinforcement Learning from Human Feedback</strong>, and it’s the approach t",
      "fromId": "web-21c4a356615bd040",
      "toId": "web-11370417f715f333",
      "weight": 0.7330729166666666,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "In our previous blog post, we introduced Volcano Engine Reinforcement Learning for LLMs (verl) 0.3.0",
      "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
      "fromId": "web-3650efa34ab90d14",
      "toId": "web-5a19838b2adf8845",
      "weight": 0.7330729166666666,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "... Structured state space sequence models (S4) are <strong>a recent class of sequence models for de",
      "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
      "fromId": "web-3d182c8a65d6c5bb",
      "toId": "web-5a19838b2adf8845",
      "weight": 0.7317708333333334,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "[2024/02] LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environme",
      "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
      "fromId": "web-00a86862246b75be",
      "toId": "web-2ae2aa60858dd99c",
      "weight": 0.7278645833333334,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "<strong>Large language model-based multi-agent systems have shown great abilities across various tas",
      "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
      "fromId": "web-2f7bfc69348d4385",
      "toId": "web-5a19838b2adf8845",
      "weight": 0.72265625,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "These LLM-based Multi-Agent Systems (MASs) <strong>enable groups of intelligent agents to coordinate",
      "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
      "fromId": "web-21c4a356615bd040",
      "toId": "web-5a19838b2adf8845",
      "weight": 0.7200520833333334,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "The predecessor to Mamba, the S4 model [6], was <strong>the first SSM to show promising results in t",
      "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
      "fromId": "web-1d616ea7698e2ed2",
      "toId": "web-5a19838b2adf8845",
      "weight": 0.71875,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "In our previous blog post, we introduced Volcano Engine Reinforcement Learning for LLMs (verl) 0.3.0",
      "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
      "fromId": "web-3650efa34ab90d14",
      "toId": "web-2ae2aa60858dd99c",
      "weight": 0.7174479166666666,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "The predecessor to Mamba, the S4 model [6], was <strong>the first SSM to show promising results in t",
      "to": "They provide the capabilities that actually make AI agents work, like <strong>multi-agent orchestrat",
      "fromId": "web-1d616ea7698e2ed2",
      "toId": "web-2ae2aa60858dd99c",
      "weight": 0.7109375,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "[2024/02] LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environme",
      "to": "The central feature of transformer models is their self-attention mechanism, from which transformer ",
      "fromId": "web-00a86862246b75be",
      "toId": "web-5a19838b2adf8845",
      "weight": 0.7044270833333334,
      "type": "jenny_coupler",
      "date": "2026-02-19 20:00:02",
      "colony": "alpha"
    },
    {
      "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
      "to": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on stan",
      "fromId": "hf-2602.15927",
      "toId": "hf-2602.16666",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
      "to": "Long-horizon multimodal agents depend on external memory; however, similarity-based retrieval often ",
      "fromId": "hf-2602.15927",
      "toId": "hf-2602.16493",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
      "to": "We report on the temporal changes in undergraduate-level physics programs at Korean universities fro",
      "fromId": "hf-2602.15927",
      "toId": "s2-41b5a001b9bc346cbf378e3c050316827828233b",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
      "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
      "fromId": "hf-2602.15927",
      "toId": "hf-2602.10210",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "Generative large vision-language models (LVLMs) have recently achieved impressive performance gains,",
      "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
      "fromId": "hf-2602.15927",
      "toId": "hf-2602.15156",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on stan",
      "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
      "fromId": "hf-2602.16666",
      "toId": "hf-2602.10210",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent re",
      "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
      "fromId": "hf-2602.16301",
      "toId": "hf-2602.10210",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent re",
      "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
      "fromId": "hf-2602.16301",
      "toId": "hf-2602.15156",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "We report on the temporal changes in undergraduate-level physics programs at Korean universities fro",
      "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
      "fromId": "s2-41b5a001b9bc346cbf378e3c050316827828233b",
      "toId": "hf-2602.10210",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reas",
      "to": "Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up",
      "fromId": "hf-2602.15382",
      "toId": "hf-2602.10210",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reas",
      "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
      "fromId": "hf-2602.15382",
      "toId": "hf-2602.15156",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:00:03",
      "colony": "alpha"
    },
    {
      "from": "Emerging trend: memory-systems with 10 related findings in the last 24h",
      "to": "Abstract: Latency optimization is crucial for deploying large language models (LLMs) in edge computi",
      "fromId": "insight-1771389602128-hei8uc",
      "toId": "s2-70ce98fdd37be3c0bf9cdfb81ea5a1f0d333da75",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: memory-systems with 10 related findings in the last 24h",
      "to": "Language models are increasingly used to reason over content they were not trained on, such as new d",
      "fromId": "insight-1771389602128-hei8uc",
      "toId": "hf-2602.15156",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Large Language Models (LLMs) have attracted extensive attention due to their remarkable performance ",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-5be7e6b04c5a240cff340034aae2b57c677e211f",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Sequence modeling is a crucial area across various domains, including Natural Language Processing (N",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-ba4c5a116d07b37dea1046b6d16a60cb2d01cd47",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Long-short range time series forecasting is essential for predicting future trends and patterns over",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-3e0aa05e9c0ee4fc6b3c67887960a9ef18c502d4",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Time series forecasting has made significant advances, including with Transformer-based models. The ",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-4ea7378fc3cb0c6e7092ae162cbd1537ae637597",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "CONNECTION: Get multimodal embeddings | Generative AI on Vertex AI | Google Cloud Documentation ↔ An",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "deep-synth-1771441567432-jhohn6",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "CONNECTION: Get multimodal embeddings | Generative AI on Vertex AI | Google Cloud Documentation ↔ An",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "deep-synth-1771420001613-jqmoc6",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Powerful foundation models, including large language models (LLMs), with Transformer architectures h",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-68719e9df3d4821a1afedf9c18b0148e51800f71",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "The Large Language Model (LLM) is widely employed for tasks such as intelligent assistants, text sum",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-1f43c1f42dd5505f27c0b36c99e6e6fa01f87ad5",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Long-term time series forecasting (LTSF) provides longer insights into future trends and patterns. O",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-bf4d1d11c0ee0c4335e8ae6f0e433e7ddd20be87",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Recent advancements in multivariate time series forecasting have been propelled by Linear-based, Tra",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-b7ed7845bfa63b07899d44434a479f08f80ca268",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "In recent years, Transformers have become the de-facto architecture for long-term sequence forecasti",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-9823f4a4c66c0607994a9f9722ec3c4cf8c1f2e4",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "In recent years, the rapid advancement of large-scale pre-trained language models based on transform",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-ac2de949adce88d5933675560d0ac449d116dea2",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Time-series forecasting has seen significant advancements with the introduction of token prediction ",
      "fromId": "insight-1771389602128-xld5wx",
      "toId": "s2-c86d4019359e33d8e00633bcb81c5722924fbbbf",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Large Language Models (LLMs) have attracted extensive attention due to their remarkable performance ",
      "fromId": "insight-1771504801451-ojs1wu",
      "toId": "s2-5be7e6b04c5a240cff340034aae2b57c677e211f",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Sequence modeling is a crucial area across various domains, including Natural Language Processing (N",
      "fromId": "insight-1771504801451-ojs1wu",
      "toId": "s2-ba4c5a116d07b37dea1046b6d16a60cb2d01cd47",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Long-short range time series forecasting is essential for predicting future trends and patterns over",
      "fromId": "insight-1771504801451-ojs1wu",
      "toId": "s2-3e0aa05e9c0ee4fc6b3c67887960a9ef18c502d4",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "Time series forecasting has made significant advances, including with Transformer-based models. The ",
      "fromId": "insight-1771504801451-ojs1wu",
      "toId": "s2-4ea7378fc3cb0c6e7092ae162cbd1537ae637597",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    },
    {
      "from": "Emerging trend: attention-mechanisms with 10 related findings in the last 24h",
      "to": "CONNECTION: Get multimodal embeddings | Generative AI on Vertex AI | Google Cloud Documentation ↔ An",
      "fromId": "insight-1771504801451-ojs1wu",
      "toId": "deep-synth-1771441567432-jhohn6",
      "weight": 0.5,
      "type": "cross_cluster",
      "date": "2026-02-19 20:10:02",
      "colony": "beta"
    }
  ],
  "topBreakthroughs": [
    {
      "topic": "web-11370417f715f333",
      "strength": 0.6863738923994217,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-19T16:30:01.464Z",
      "colony": "alpha"
    },
    {
      "topic": "web-5a19838b2adf8845",
      "strength": 0.6698358639690458,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-19T16:30:01.612Z",
      "colony": "alpha"
    },
    {
      "topic": "web-e966420a37acc61d",
      "strength": 0.3715831234831065,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-19T00:15:02.808Z",
      "colony": "alpha"
    },
    {
      "topic": "web-e966420a37acc61d",
      "strength": 0.371581088038905,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-19T00:15:02.852Z",
      "colony": "alpha"
    },
    {
      "topic": "web-e966420a37acc61d",
      "strength": 0.37158053066769114,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T21:15:01.892Z",
      "colony": "alpha"
    },
    {
      "topic": "web-e966420a37acc61d",
      "strength": 0.37157831357713905,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T20:30:02.144Z",
      "colony": "alpha"
    },
    {
      "topic": "web-2228e576bf95e522",
      "strength": 0.3619199988244031,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-19T00:30:01.525Z",
      "colony": "alpha"
    },
    {
      "topic": "PostgreSQL Hash Chain Audit Pattern",
      "strength": 0.23390043139100608,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T12:25:01.969Z",
      "colony": "beta"
    },
    {
      "topic": "PostgreSQL Hash Chain Audit Pattern",
      "strength": 0.23389879929146792,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T10:22:39.938Z",
      "colony": "beta"
    },
    {
      "topic": "PostgreSQL Time-Series Partitioning for Audit Logs",
      "strength": 0.22651266739388887,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T10:22:39.996Z",
      "colony": "beta"
    },
    {
      "topic": "Merkle Tree Anchors for Audit Checkpoints",
      "strength": 0.22158860946331416,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T10:22:40.049Z",
      "colony": "beta"
    },
    {
      "topic": "web-24ace1ccaf1a4193",
      "strength": 0.21585599234294492,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T12:30:01.729Z",
      "colony": "alpha"
    },
    {
      "topic": "oalex-W3044091938",
      "strength": 0.19610672961795564,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T10:06:06.010Z",
      "colony": "alpha"
    },
    {
      "topic": "oalex-W3207559276",
      "strength": 0.19604337559039872,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T10:05:36.930Z",
      "colony": "alpha"
    },
    {
      "topic": "oalex-W3015606043",
      "strength": 0.19553075096629358,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T10:11:41.155Z",
      "colony": "gamma"
    },
    {
      "topic": "oalex-W2181465509",
      "strength": 0.1954361716461569,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T08:40:01.322Z",
      "colony": "beta"
    },
    {
      "topic": "oalex-W2115765852",
      "strength": 0.19543593495138126,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T08:40:01.213Z",
      "colony": "beta"
    },
    {
      "topic": "s2-1df0f2e6e83b77807343793b66466d9c2571534a",
      "strength": 0.19524412632908394,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T10:09:29.129Z",
      "colony": "gamma"
    },
    {
      "topic": "s2-0b25979bf487cbc9334e0e94031cdac83d4f28dd",
      "strength": 0.1952250475714077,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T10:09:20.334Z",
      "colony": "gamma"
    },
    {
      "topic": "s2-d0489fd7c5ff833e08969341ae6e5fa1d0e6dd2a",
      "strength": 0.1951966422245158,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T10:09:07.238Z",
      "colony": "gamma"
    },
    {
      "topic": "web-1eaf00d7a315d346",
      "strength": 0.1908388884934991,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T08:30:02.098Z",
      "colony": "alpha"
    },
    {
      "topic": "web-1eaf00d7a315d346",
      "strength": 0.19083855558595067,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T08:30:01.941Z",
      "colony": "alpha"
    },
    {
      "topic": "web-1c2445d4eb57c6f7",
      "strength": 0.19083830749598965,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T08:30:01.824Z",
      "colony": "alpha"
    },
    {
      "topic": "hf-2602.09877",
      "strength": 0.18097603452439504,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T08:05:39.511Z",
      "colony": "alpha"
    },
    {
      "topic": "hf-2602.12036",
      "strength": 0.18055214092444333,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T08:12:08.257Z",
      "colony": "beta"
    },
    {
      "topic": "hf-2602.09021",
      "strength": 0.1804544605628336,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T08:11:19.553Z",
      "colony": "beta"
    },
    {
      "topic": "oalex-W2912320302",
      "strength": 0.16713595874947257,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T06:06:19.380Z",
      "colony": "alpha"
    },
    {
      "topic": "arxiv-2602.15010v1",
      "strength": 0.16638560875157293,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T06:09:34.289Z",
      "colony": "gamma"
    },
    {
      "topic": "oalex-W2115765852",
      "strength": 0.16622267690023126,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T06:08:06.041Z",
      "colony": "beta"
    },
    {
      "topic": "oalex-W4321013654",
      "strength": 0.1537521403657728,
      "type": "breakthrough",
      "insight": "",
      "source": "",
      "date": "2026-02-18T04:11:07.257Z",
      "colony": "beta"
    }
  ]
}